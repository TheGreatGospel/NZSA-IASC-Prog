\documentclass[12pt]{article}
% \documentstyle{iascars2017}

% \usepackage{iascars2017}

\pagestyle{myheadings} 
\pagenumbering{arabic}
\topmargin 0pt \headheight 23pt \headsep 24.66pt
%\topmargin 11pt \headheight 12pt \headsep 13.66pt
\parindent = 3mm 


\begin{document}


\begin{flushleft}


{\LARGE\bf Covariate Discretisation on Big Data}


\vspace{1.0cm}

Hon Hwang$^{1,2}$, Stephen Wright$^{2,3}$, and Louise Ryan$^{1,2}$ 

\begin{description}

\item $^1 \;$ The University of Technology Sydney (UTS)
\item $^2 \;$ The Australian Research Council (ARC) Centre of Excellence for Mathematical and Statistical Frontiers (ACEMS)
\item $^3 \;$ Australian Red Cross Blood Service



\end{description}

\end{flushleft}

%  ***** ADD ENOUGH VERTICAL SPACE HERE TO ENSURE THAT THE *****
%  ***** ABSTRACT (OR MAIN TEXT) STARTS 5 CM BELOW THE TOP *****

\vspace{0.75cm}

\noindent


\noindent {\bf Abstract}. Distributed Computing Systems such as Hadoop and Spark allowstatistical analysis to be performed on arbitrary large datasets. However,when performing statistical analysis on these systems, the data communicationbetween the nodes of a distributed computing system can become a major performancebottleneck. In this work, we outline a novel combination of statistical andcomputation techniques to address this issue.
We first apply data reduction technique such as coarsening (interval-censoring) on
large data sets using a distributed computing system.
We then perform statistical analysis on the coarsened data.
However, performing analysis using coarsened data potentially introduces biases
in the results.
To address this, we use the Expectation-Maximisation (EM) algorithm to recoverthe complete (non-coarsened) data model. Our work draws on methods forthe analysis of data involving coarsened co-variates using EM by methodsof weights. We explore different coarsening strategies (e.g., rounding, quantileand quintile) and discuss how our methods can scale to very large datasettings. Through simulation studies, we find our method works especiallywell when data is coarsened from a wide interval, where there are moreloss of information. Compared with na\"{i}vely using the coarsened data,
our method is able to estimate regression coefficients that are closer to
estimates obtained from using the complete data. In addition, the standard
errors from our method reflect more accurately the uncertainty arising from
using coarsened data.

%If an abstract is included, it should be
%set in the same type as the main text, with the same line width
%and line spacing, starting 15 lines (typewriter) or 5 cm
%(PC) below the top of the print area; otherwise the first
%heading starts here.

\vskip 2mm

\noindent {\bf Keywords}.
EM algorithm, coarsened data, regression, big data


%\section{ First-level heading}
%The C98 head 1 style leaves a half-line spacing below a
%first-level heading. There should be one blank line above
%a first-level heading.
%        
%\subsection { Second-level heading}
%There should also be one blank line above a second- or
%third-level heading (but no extra space below them).
%
%Do not intent the first paragraph following a heading.
%Second and subsequent paragraphs are indented by one Tab
%character (= 3 mm). If footnotes are used, they should be
%placed at the foot of the page\footnote{ Footnotes are separated
%from the text by a blank line and a printed line of length 3.5 cm.
%They should be printed in 9-point Times Roman in single line spacing.}.
%        
%\subsubsection { Third-level heading}
%Please specify references using the conventions
%illustrated below. Each should begin on a new line, and
%second and subsequent lines should be on the same page
%indented by 3 mm.

%\subsection*{References}
%
%\begin{description}
%
%\item
%Barnett, J.A., Payne, R.W. and Yarrow, D. (1990).
%\textit{Yeasts: Characteristics and identification: Second Edition.}
%Cambridge: Cambridge University Press.
%
%\item
%(ed.) Barnett, V., Payne, R. and Steiner, R. (1995).
%\textit{Agricultural Sustainability: Economic, Environmental and
%Statistical Considerations}. Chichester: Wiley.
%
%\item
%Payne, R.W. (1997).
%\textit{Algorithm AS314 Inversion of matrices Statistics},
%\textbf{46}, 295--298.
%
%\item
%Payne, R.W. and Welham, S.J. (1990).
%A comparison of algorithms for combination of information in generally
%balanced designs.
%In: \textit{COMPSTAT90 Proceedings in Computational Statistics}, 297--302.
%Heidelberg: Physica-Verlag.
%
%\end{description}

\end{document}





