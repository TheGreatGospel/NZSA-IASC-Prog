\documentclass[12pt]{article}
% \documentstyle{iascars2017}

% \usepackage{iascars2017}

\pagestyle{myheadings} 
\pagenumbering{arabic}
\topmargin 0pt \headheight 23pt \headsep 24.66pt
%\topmargin 11pt \headheight 12pt \headsep 13.66pt
\parindent = 3mm 


\begin{document}


\begin{flushleft}


{\LARGE\bf A Practitioners Guide to Deep Learning for Predictive Analytics on Structured Data}


\vspace{1.0cm}

Balaram Panda$^1$ and Habib Baluwala Ph.D.(University of Oxford)$^2$

\begin{description}

\item $^1 \;$ Data Scientist, Inland Revenue Department, New Zealand

\item $^2 \;$ Data Scientist, Inland Revenue Department, New Zealand

\end{description}

\end{flushleft}

%  ***** ADD ENOUGH VERTICAL SPACE HERE TO ENSURE THAT THE *****
%  ***** ABSTRACT (OR MAIN TEXT) STARTS 5 CM BELOW THE TOP *****

\vspace{0.75cm}

\noindent {\bf Abstract}. Recently, deep learning techniques have shown remarkably strong performance in problems involving unstructured data (ex. text, image, and video). One of the reasons for this success is the ability of deep learning methods to learn multiple levels of abstraction and feature interaction. However, the advantages of using deep learning techniques for structured/ event/transactional data has not been studied in detail.  The purpose of this paper is to review the advantages and limitations of using deep feed forward networks on structured data. This is achieved by comparing the performance of deep feed forward networks with conventional machine learning techniques applied on a large structured dataset for classification problem. The paper also describes methodologies for optimizing the deep feed forward networks to achieve better accuracy and  different approaches to reduce over fitting for deep feed forward network. A sensitivity analysis is conducted to explore the effect of hyper parameter tuning on model performance.  We also derive practical advice from our extensive empirical results for those interested in getting most out of deep feed forward networks for real world settings.

\vskip 2mm

\noindent {\bf Keywords}.
Deep Learning, deep feed forward networks, machine learning, R, Tensorflow, Python 


%\section{ First-level heading}
%The C98 head 1 style leaves a half-line spacing below a
%first-level heading. There should be one blank line above
%a first-level heading.
%        
%\subsection { Second-level heading}
%There should also be one blank line above a second- or
%third-level heading (but no extra space below them).
%
%Do not intent the first paragraph following a heading.
%Second and subsequent paragraphs are indented by one Tab
%character (= 3 mm). If footnotes are used, they should be
%placed at the foot of the page\footnote{ Footnotes are separated
%from the text by a blank line and a printed line of length 3.5 cm.
%They should be printed in 9-point Times Roman in single line spacing.}.
%        
%\subsubsection { Third-level heading}
%Please specify references using the conventions
%illustrated below. Each should begin on a new line, and
%second and subsequent lines should be on the same page
%indented by 3 mm.

\subsection*{References}

\begin{description}

\item
Bengio, Yoshua. "Learning deep architectures for AI." Foundations and trendsÂ® in Machine Learning 2.1 (2009): 1-127.

\item
Goodfellow, Ian J., et al. "Maxout networks." arXiv preprint arXiv:1302.4389 (2013).

\end{description}

\end{document}





